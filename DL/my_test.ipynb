{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T12:05:59.195244Z",
     "start_time": "2023-01-30T12:05:57.840609Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from nats_bench import create\n",
    "from torch import nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.nn import functional as F\n",
    "import xautodl\n",
    "from xautodl.datasets.DownsampledImageNet import ImageNet16\n",
    "from xautodl.datasets.SearchDatasetWrap import SearchDataset\n",
    "from xautodl.config_utils import load_config\n",
    "import torch\n",
    "import torchvision.models as M\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from xautodl.models import get_cell_based_tiny_net\n",
    "\n",
    "#from datatest import get_valid_test_loader, ECELoss, AdaptiveECELoss, ClasswiseECELoss, get_logits_labels\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'NVIDIA GeForce RTX 2070 with Max-Q Design'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T13:02:24.104828Z",
     "start_time": "2023-01-30T13:02:24.088877Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_loader(dataset, batch):\n",
    "    data_dir = 'D:\\\\Datasets\\\\Cifar\\\\cifar-10-python\\\\cifar-10-python'\n",
    "\n",
    "    if dataset == \"cifar10\":\n",
    "        normalize = transforms.Normalize(\n",
    "            mean=[x / 255 for x in [125.3, 123.0, 113.9]],\n",
    "            std=[x / 255 for x in [63.0, 62.1, 66.7]],\n",
    "        )\n",
    "\n",
    "        # define transform\n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "        data = datasets.CIFAR10(\n",
    "            root=data_dir, train=True,\n",
    "            download=True, transform=transform,\n",
    "        )\n",
    "\n",
    "        num_train = len(data)\n",
    "        # print(\"num_train:{}\".format(num_train))\n",
    "        indices = list(range(num_train))\n",
    "        split = int(np.floor(0.1 * num_train))\n",
    "        # split = 0\n",
    "\n",
    "        np.random.seed(1)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "        train_sampler = SubsetRandomSampler(train_idx)\n",
    "        valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(\n",
    "            data, batch_size=batch, sampler=train_sampler,\n",
    "            num_workers=1, pin_memory=True,\n",
    "        )\n",
    "        valid_loader = torch.utils.data.DataLoader(\n",
    "            data, batch_size=batch, sampler=valid_sampler,\n",
    "            num_workers=1, pin_memory=True,\n",
    "        )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def get_test_loader(batch_size,\n",
    "                    shuffle=True,\n",
    "                    num_workers=1,\n",
    "                    pin_memory=True):\n",
    "    normalize = transforms.Normalize(\n",
    "        mean=[x / 255 for x in [125.3, 123.0, 113.9]],\n",
    "        std=[x / 255 for x in [63.0, 62.1, 66.7]],\n",
    "    )\n",
    "\n",
    "    # define transform\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])\n",
    "\n",
    "    data_dir = 'D:\\\\Datasets\\\\Cifar\\\\cifar-10-python\\\\cifar-10-python'\n",
    "    # data_dir = '/media/linwei/disk1/NATS-Bench/cifar.python'\n",
    "    dataset = datasets.CIFAR10(\n",
    "        root=data_dir, train=False,\n",
    "        download=True, transform=transform,\n",
    "    )\n",
    "\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=shuffle,\n",
    "        num_workers=num_workers, pin_memory=pin_memory,\n",
    "    )\n",
    "\n",
    "    return data_loader\n",
    "\n",
    "def get_logits_labels(data_loader, net):\n",
    "    logits_list = []\n",
    "    labels_list = []\n",
    "    net.eval()\n",
    "    for data, label in data_loader:\n",
    "        data = data.cuda(0)\n",
    "        logits = net(data)\n",
    "        logits_list.append(logits)\n",
    "        labels_list.append(label)\n",
    "        logits = torch.cat(logits_list).cpu()\n",
    "        labels = torch.cat(labels_list).cpu()\n",
    "    return logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T12:06:03.730761Z",
     "start_time": "2023-01-30T12:06:02.078287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to D:\\Datasets\\Cifar\\cifar-10-python\\cifar-10-python\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/170498071 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3a8fb8024e484b5f9b4ad3415e42491e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting D:\\Datasets\\Cifar\\cifar-10-python\\cifar-10-python\\cifar-10-python.tar.gz to D:\\Datasets\\Cifar\\cifar-10-python\\cifar-10-python\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\ml\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\Anaconda\\envs\\ml\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\36101/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0.00/97.8M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "975f2e99f5144e2aba1615f1c4e0f00b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = 'D:\\\\Datasets\\\\Cifar\\\\cifar-10-python\\\\cifar-10-python'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "dset = 'cifar10'\n",
    "\n",
    "testloader = get_test_loader(batch_size=256)\n",
    "trainloader, valloader = get_train_loader(dset, batch=256)\n",
    "\n",
    "model = M.resnet50(pretrained=True)\n",
    "dim_in = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=dim_in, out_features=100, bias=True)\n",
    "model = model.cuda(0)\n",
    "\n",
    "epochs = 350\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, weight_decay=0.0005, momentum=0.9, nesterov=True)\n",
    "\n",
    "warmups = 20 * len(trainloader)\n",
    "\n",
    "lamda = lambda curiter: curiter / warmups if curiter < warmups else \\\n",
    "    (0.001 + 0.5 * 0.9 * (1.0 + math.cos((curiter - warmups) / ((epochs - 20) * len(trainloader)) * math.pi)))\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lamda)\n",
    "lossfunction = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T12:06:48.128132Z",
     "start_time": "2023-01-30T12:06:46.031495Z"
    }
   },
   "outputs": [],
   "source": [
    "for i, (input, label) in enumerate(trainloader):\n",
    "    a = input\n",
    "    b = label\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T12:06:55.391495Z",
     "start_time": "2023-01-30T12:06:54.375413Z"
    }
   },
   "outputs": [],
   "source": [
    "logits = model(a.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T12:20:23.765789Z",
     "start_time": "2023-01-30T12:20:23.749787Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([ 0.1604,  0.8685,  0.2373, -0.4165, -0.1285,  0.7005,  0.1664, -0.1828,\n        -0.3752, -0.9446, -0.2734, -0.6405,  0.6580, -0.0781,  0.3323, -0.6156,\n         0.0332, -0.5873, -0.3022,  0.1321,  0.0157,  0.5818, -0.4021, -0.0373,\n        -0.0191, -0.5799, -0.3191, -0.6725,  0.3245,  0.3147, -0.2908, -0.3334,\n         0.6438,  0.2544,  0.4905,  0.0592, -0.3508,  1.0222, -0.6164, -0.3681,\n         0.4904, -0.0394, -0.3722,  0.4979,  0.5271, -0.0428,  0.5845, -0.0318,\n         0.0426, -0.1796,  0.6308, -0.0752, -0.1816, -0.2019, -0.5120,  0.2559,\n        -0.5318, -0.4357, -0.6026,  0.3086, -0.8183, -0.0047, -0.5794, -0.3625,\n        -0.9270,  0.4722,  0.8223, -0.4421, -0.2141, -0.5101, -0.2315, -0.3339,\n         0.3589,  0.0891, -0.0574, -0.5132,  0.0861, -0.4465,  0.2206,  0.5878,\n        -0.3854, -0.3552,  0.4350,  0.0663,  0.5761,  0.1743, -0.2976, -0.5073,\n        -0.4644, -0.1930, -0.2676, -0.5512,  0.1851, -0.7310,  0.3737, -0.0283,\n        -0.2826, -0.1881, -0.2597, -0.4261], device='cuda:0',\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T12:06:57.214314Z",
     "start_time": "2023-01-30T12:06:57.197262Z"
    }
   },
   "outputs": [],
   "source": [
    "loss = lossfunction(logits, b.cuda(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T13:18:15.931837Z",
     "start_time": "2023-01-30T13:02:26.867452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch: 1, Val_acc:0.00860000029206276\n",
      "Current epoch: 2, Val_acc:0.13860000669956207\n",
      "Current epoch: 3, Val_acc:0.03460000082850456\n",
      "Current epoch: 4, Val_acc:0.008200000040233135\n",
      "Current epoch: 5, Val_acc:0.004399999976158142\n",
      "Current epoch: 6, Val_acc:0.009800000116229057\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 16\u001B[0m\n\u001B[0;32m     13\u001B[0m label \u001B[38;5;241m=\u001B[39m label\u001B[38;5;241m.\u001B[39mcuda(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 16\u001B[0m logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m#print(logits)\u001B[39;00m\n\u001B[0;32m     18\u001B[0m loss \u001B[38;5;241m=\u001B[39m lossfunction(logits, label)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torchvision\\models\\resnet.py:285\u001B[0m, in \u001B[0;36mResNet.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 285\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_forward_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torchvision\\models\\resnet.py:273\u001B[0m, in \u001B[0;36mResNet._forward_impl\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    270\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(x)\n\u001B[0;32m    271\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmaxpool(x)\n\u001B[1;32m--> 273\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayer1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    274\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer2(x)\n\u001B[0;32m    275\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayer3(x)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torchvision\\models\\resnet.py:151\u001B[0m, in \u001B[0;36mBottleneck.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m    148\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[0;32m    150\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv2(out)\n\u001B[1;32m--> 151\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbn2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(out)\n\u001B[0;32m    154\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv3(out)\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32mD:\\Anaconda\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:148\u001B[0m, in \u001B[0;36m_BatchNorm.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrack_running_stats:\n\u001B[0;32m    146\u001B[0m     \u001B[38;5;66;03m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001B[39;00m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_batches_tracked \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[1;32m--> 148\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_batches_tracked\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[has-type]\u001B[39;00m\n\u001B[0;32m    149\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmomentum \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:  \u001B[38;5;66;03m# use cumulative moving average\u001B[39;00m\n\u001B[0;32m    150\u001B[0m             exponential_average_factor \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mfloat\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_batches_tracked)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_model_dict = {}\n",
    "ep_num = 0\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "ep_list = []\n",
    "for epoch in range(epochs):\n",
    "    ep_list.append(epoch)\n",
    "    #print(ep_list)\n",
    "    for i, (input, label) in enumerate(trainloader):\n",
    "        model.train()\n",
    "        input = input.cuda(0)\n",
    "        label = label.cuda(0)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(input)\n",
    "        #print(logits)\n",
    "        loss = lossfunction(logits, label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits, labels = get_logits_labels(valloader, model)\n",
    "        softmaxes = F.softmax(logits, dim=0)\n",
    "        _, predictions = torch.max(softmaxes, 1)\n",
    "        acc = predictions.eq(labels).float().mean().item()\n",
    "        print(\"Current epoch: {}, Val_acc:{}\".format(epoch+1, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T13:52:20.039350Z",
     "start_time": "2023-01-30T13:52:17.091463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.3524), 0.049374282360076904]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    info = []\n",
    "    logits, labels = get_logits_labels(testloader, model)\n",
    "    softmaxes = F.softmax(logits, dim=0)\n",
    "    _, predictions = torch.max(softmaxes, 1)\n",
    "    nacc = predictions.eq(labels).float().mean()\n",
    "    info.append(nacc)\n",
    "    ece_criterion = ECELoss().cuda(0)\n",
    "    nece = ece_criterion(logits, labels).item()\n",
    "    info.append(nece)\n",
    "\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-30T13:51:59.928913Z",
     "start_time": "2023-01-30T13:51:59.918940Z"
    }
   },
   "outputs": [],
   "source": [
    "class ECELoss(nn.Module):\n",
    "    '''\n",
    "    Compute ECE (Expected Calibration Error)\n",
    "    '''\n",
    "    def __init__(self, n_bins=15):\n",
    "        super(ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClasswiseECELoss(nn.Module):\n",
    "    '''\n",
    "    Compute Classwise ECE\n",
    "    '''\n",
    "    def __init__(self, n_bins=15):\n",
    "        super(ClasswiseECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        num_classes = int((torch.max(labels) + 1).item())\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        per_class_sce = None\n",
    "\n",
    "        for i in range(num_classes):\n",
    "            class_confidences = softmaxes[:, i]\n",
    "            class_sce = torch.zeros(1, device=logits.device)\n",
    "            labels_in_class = labels.eq(i) # one-hot vector of all positions where the label belongs to the class i\n",
    "\n",
    "            for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "                in_bin = class_confidences.gt(bin_lower.item()) * class_confidences.le(bin_upper.item())\n",
    "                prop_in_bin = in_bin.float().mean()\n",
    "                if prop_in_bin.item() > 0:\n",
    "                    accuracy_in_bin = labels_in_class[in_bin].float().mean()\n",
    "                    avg_confidence_in_bin = class_confidences[in_bin].mean()\n",
    "                    class_sce += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "            if (i == 0):\n",
    "                per_class_sce = class_sce\n",
    "            else:\n",
    "                per_class_sce = torch.cat((per_class_sce, class_sce), dim=0)\n",
    "\n",
    "        sce = torch.mean(per_class_sce)\n",
    "        return sce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveECELoss(nn.Module):\n",
    "    '''\n",
    "    Compute Adaptive ECE\n",
    "    '''\n",
    "    def __init__(self, n_bins=15):\n",
    "        super(AdaptiveECELoss, self).__init__()\n",
    "        self.nbins = n_bins\n",
    "\n",
    "    def histedges_equalN(self, x):\n",
    "        npt = len(x)\n",
    "        return np.interp(np.linspace(0, npt, self.nbins + 1),\n",
    "                     np.arange(npt),\n",
    "                     np.sort(x))\n",
    "    def forward(self, logits, labels):\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "        n, bin_boundaries = np.histogram(confidences.cpu().detach(), self.histedges_equalN(confidences.cpu().detach()))\n",
    "        #print(n,confidences,bin_boundaries)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.3524), 0.014100000262260437]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    info = []\n",
    "    logits, labels = get_logits_labels(testloader, model)\n",
    "    softmaxes = F.softmax(logits, dim=0)\n",
    "    _, predictions = torch.max(softmaxes, 1)\n",
    "    nacc = predictions.eq(labels).float().mean()\n",
    "    info.append(nacc)\n",
    "    ece_criterion = ClasswiseECELoss().cuda(0)\n",
    "    nece = ece_criterion(logits, labels).item()\n",
    "    info.append(nece)\n",
    "\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.3524), 0.04938226193189621]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    info = []\n",
    "    logits, labels = get_logits_labels(testloader, model)\n",
    "    softmaxes = F.softmax(logits, dim=0)\n",
    "    _, predictions = torch.max(softmaxes, 1)\n",
    "    nacc = predictions.eq(labels).float().mean()\n",
    "    info.append(nacc)\n",
    "    ece_criterion = AdaptiveECELoss().cuda(0)\n",
    "    nece = ece_criterion(logits, labels).item()\n",
    "    info.append(nece)\n",
    "\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MECELoss(nn.Module):\n",
    "    '''\n",
    "    Compute MECE (Expected Calibration Error)\n",
    "    '''\n",
    "    def __init__(self, n_bins=15):\n",
    "        super(MECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, logits, labels):\n",
    "        softmaxes = F.softmax(logits, dim=1)\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        ece = torch.zeros(1, device=logits.device)\n",
    "        mece = []\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "                mece.append(torch.abs(avg_confidence_in_bin - accuracy_in_bin))\n",
    "        print(mece)\n",
    "\n",
    "        return max(mece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.0643), tensor(0.1126), tensor(0.0517), tensor(0.0376), tensor(0.0434), tensor(0.1208), tensor(0.0593), tensor(0.1137), tensor(0.0727), tensor(0.0910), tensor(0.0989), tensor(0.0244)]\n",
      "[tensor(0.3523), 0.12081539630889893]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    info = []\n",
    "    logits, labels = get_logits_labels(testloader, model)\n",
    "    softmaxes = F.softmax(logits, dim=0)\n",
    "    _, predictions = torch.max(softmaxes, 1)\n",
    "    nacc = predictions.eq(labels).float().mean()\n",
    "    info.append(nacc)\n",
    "    ece_criterion = MECELoss().cuda(0)\n",
    "    nece = ece_criterion(logits, labels).item()\n",
    "    info.append(nece)\n",
    "\n",
    "    print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2eb7584621a2f4ee96e111ace36f07a0703de43d9fe13a401bcc72e363b8869b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
